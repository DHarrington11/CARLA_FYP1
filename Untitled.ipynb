{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44339ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# sem_list = [name for name in os.listdir('/home/dh26/Documents/Carla/gym-carla/Unet_images/Sunny/Semantic/')]\n",
    "# for name in sem_list:\n",
    "#     old_name = '/home/dh26/Documents/Carla/gym-carla/images/Semantic/{}'.format(name)\n",
    "#     name=name[9:]\n",
    "#     new_name = '/home/dh26/Documents/Carla/gym-carla/images/Semantic/{}'.format(name)\n",
    "#     os.rename(old_name,new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab37b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_list = [name for name in os.listdir('/home/dh26/Documents/Carla/gym-carla/Unet_images/Sunny/Semantic/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11a89c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2537"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea827e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_name = r\"E:\\demos\\files\\reports\\details.txt\"\n",
    "new_name = r\"E:\\demos\\files\\reports\\new_details.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5acaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb_list = [name for name in os.listdir('/home/dh26/Documents/Carla/gym-carla/images/RGB/')]\n",
    "# for name in rgb_list:\n",
    "#     old_name = '/home/dh26/Documents/Carla/gym-carla/images/RGB/{}'.format(name)\n",
    "#     name=name[9:]\n",
    "#     new_name = '/home/dh26/Documents/Carla/gym-carla/images/RGB/{}'.format(name)\n",
    "#     os.rename(old_name,new_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ff9f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2586"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_list = [name for name in os.listdir('/home/dh26/Documents/Carla/gym-carla/Unet_images/Sunny/RGB/')]\n",
    "len(rgb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e269b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffSem=[]\n",
    "for name in sem_list:\n",
    "    if name not in rgb_list:\n",
    "        diffSem.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64382cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffRGB=[]\n",
    "for name in rgb_list:\n",
    "    if name not in sem_list:\n",
    "        diffRGB.append(name)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223d56b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1304"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diffRGB)\n",
    "#45878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58b3afc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diffSem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "844ed7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diffRGB)-len(diffSem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3049f137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72522"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rgb_list) - len(diffRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581cae41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72522"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sem_list) - len(diffSem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff8fa09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'180399.png'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffSem[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d253155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in diffRGB:\n",
    "    path = '/home/dh26/Documents/Carla/gym-carla/images/RGB/{}'.format(name)\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad204834",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in diffSem:\n",
    "    path = '/home/dh26/Documents/Carla/gym-carla/images/Semantic/{}'.format(name)\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d965e1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72522"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem_list = [name for name in os.listdir('/home/dh26/Documents/Carla/gym-carla/images/Semantic/')]\n",
    "len(sem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf096957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72522"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_list = [name for name in os.listdir('/home/dh26/Documents/Carla/gym-carla/images/RGB/')]\n",
    "len(rgb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2606f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/home/dh26/Documents/Carla/gym-carla/images/RGB/'\n",
    "image_list = os.listdir(image_path)\n",
    "image_list = [image_path+i for i in image_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9dad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "img = imageio.imread(image_list[0])\n",
    "img = img[:,:,:3]\n",
    "img = img.reshape(3,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037815ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faa1cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_list = [name for name in os.listdir('/home/dh26/Documents/Carla/gym-carla/images/RGB_test/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6956f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_list = [name for name in os.listdir('/home/dh26/Documents/Carla/gym-carla/images/Semantic_test/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b22b726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffSem=[]\n",
    "for name in sem_list:\n",
    "    if name not in rgb_list:\n",
    "        diffSem.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bfb69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffRGB=[]\n",
    "for name in rgb_list:\n",
    "    if name not in sem_list:\n",
    "        diffRGB.append(name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d1d25aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diffRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c1ead23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diffSem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2033450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb1561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc93b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in diffRGB:\n",
    "    path = '/home/dh26/Documents/Carla/gym-carla/images/RGB_test/{}'.format(name)\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23c4955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffRGB=[]\n",
    "for name in rgb_list:\n",
    "    if name not in sem_list:\n",
    "        diffRGB.append(name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b2991cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffRGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26f0e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.7.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from select import select\n",
    "import gym\n",
    "import gym_carla\n",
    "import carla\n",
    "from gym_carla.envs.dqn import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e26852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "from collections import deque,namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58de08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "from gym.wrappers import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d9ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, state_space,action_space):\n",
    "        super(DQN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(state_space, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25,15),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8 ,action_space),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.learning_rate = 0.001\n",
    "        self.optimiser = optim.Adam(self.parameters(), self.learning_rate)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "200d3a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, next_state, reward):\n",
    "        # Add the tuple (state, action, next_state, reward) to the queue\n",
    "        self.memory.append((state, action, next_state, reward))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch_size = min(batch_size, len(self)) \n",
    "        return random.sample(self.memory,batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c292ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action_epsilon_greedy(net, state, epsilon):\n",
    "    \n",
    "    if epsilon > 1 or epsilon < 0:\n",
    "        raise Exception('The epsilon value must be between 0 and 1')\n",
    "                \n",
    "    # Evaluate the network output from the current state\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        state = torch.tensor(state, dtype=torch.float32) # Convert the state to tensor\n",
    "        net_out = net(state)\n",
    "\n",
    "    # Get the best action (argmax of the network output)\n",
    "    best_action = int(net_out.argmax())\n",
    "    # Get the number of possible actions\n",
    "    action_space_dim = net_out.shape[-1]\n",
    "\n",
    "    # Select a non optimal action with probability epsilon, otherwise choose the best action\n",
    "    if random.random() < epsilon:\n",
    "        # List of non-optimal actions (this list includes all the actions but the optimal one)\n",
    "        non_optimal_actions = [a for a in range(action_space_dim) if a != best_action]\n",
    "        # Select randomly from non_optimal_actions\n",
    "        action = random.choice(non_optimal_actions)\n",
    "    else:\n",
    "        # Select best action\n",
    "        action = best_action\n",
    "        \n",
    "    return action, net_out.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7a9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action_softmax(net, state, temperature):\n",
    "    \n",
    "    if temperature < 0:\n",
    "        raise Exception('The temperature value must be greater than or equal to 0 ')\n",
    "        \n",
    "    # If the temperature is 0, just select the best action using the eps-greedy policy with epsilon = 0\n",
    "    if temperature == 0:\n",
    "        return choose_action_epsilon_greedy(net, state, 0)\n",
    "    \n",
    "    # Evaluate the network output from the current state\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        state = torch.tensor(state, dtype=torch.float32)\n",
    "        net_out = net(state)\n",
    "\n",
    "    # Apply softmax with temp\n",
    "    temperature = max(temperature, 1e-8) # set a minimum to the temperature for numerical stability\n",
    "    softmax_out = nn.functional.softmax(net_out/temperature, dim=0).cpu().numpy()\n",
    "                \n",
    "    # Sample the action using softmax output as mass pdf\n",
    "    all_possible_actions = np.arange(0, softmax_out.shape[-1])\n",
    "    # this samples a random element from \"all_possible_actions\" with the probability distribution p (softmax_out in this case)\n",
    "    action = np.random.choice(all_possible_actions,p=softmax_out)\n",
    "    \n",
    "    return action, net_out.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f64a0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define exploration profile\n",
    "initial_value = 5\n",
    "num_iterations = 800\n",
    "exp_decay = np.exp(-np.log(initial_value) / num_iterations * 6) \n",
    "exploration_profile = [initial_value * (exp_decay ** i) for i in range(num_iterations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5493f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():# parameters for the gym_carla environment\n",
    "    params = {\n",
    "    'number_of_vehicles': 0,\n",
    "    'number_of_walkers': 0,\n",
    "    'display_size': 256,  # screen size of bird-eye render\n",
    "    'max_past_step': 1,  # the number of past steps to draw\n",
    "    'dt': 0.1,  # time interval between two frames\n",
    "    'discrete': True,  # whether to use discrete control space\n",
    "    'discrete_acc': [-3.0, 0.0, 3.0],  # discrete value of accelerations\n",
    "    'discrete_steer': [-0.4, 0.0, 0.4],  # discrete value of steering angles\n",
    "    'continuous_accel_range': [-3.0, 3.0],  # continuous acceleration range\n",
    "    'continuous_steer_range': [-0.3, 0.3],  # continuous steering angle range\n",
    "    'ego_vehicle_filter': 'vehicle.tesla.model3',  # filter for defining ego vehicle\n",
    "    'port': 2000,  # connection port\n",
    "    'town': 'Town03',  # which town to simulate\n",
    "    'task_mode': 'random',  # mode of the task, [random, roundabout (only for Town03)]\n",
    "    'max_time_episode': 1000,  # maximum timesteps per episode\n",
    "    'max_waypt': 12,  # maximum number of waypoints\n",
    "    'obs_range': 32,  # observation range (meter)\n",
    "    'lidar_bin': 0.125,  # bin size of lidar sensor (meter)\n",
    "    'd_behind': 12,  # distance behind the ego vehicle (meter)\n",
    "    'out_lane_thres': 2.0,  # threshold for out of lane\n",
    "    'desired_speed': 6,  # desired speed (m/s)\n",
    "    'max_ego_spawn_times': 200,  # maximum times to spawn ego vehicle\n",
    "    'display_route': True,  # whether to render the desired route\n",
    "    'pixor_size': 64,  # size of the pixor labels\n",
    "    'pixor': False,  # whether to output PIXOR observation\n",
    "    'dynamic_weather':False, #Set TRUE for random weather\n",
    "  };\n",
    "    env = gym.make('carla-v0', params=params) \n",
    "    env.seed(0) # Set a random seed for the environment\n",
    "    \n",
    "    state_space_dim = 9\n",
    "    action_space_dim = env.action_space.n\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Set random seeds\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    gamma = 0.99  \n",
    "    replay_memory_capacity = 10000   \n",
    "    lr = 1e-3\n",
    "    target_net_update_steps = 10   \n",
    "    batch_size = 256   \n",
    "    bad_state_penalty = 0   \n",
    "    min_samples_for_training = 1000   \n",
    "\n",
    "    # replay memory\n",
    "    replay_mem = ReplayMemory(replay_memory_capacity)    \n",
    "\n",
    "    # policy network\n",
    "    policy_net = DQN(state_space_dim, action_space_dim).to(device)\n",
    "\n",
    "    # target network with the same weights of the policy network\n",
    "    target_net = DQN(state_space_dim, action_space_dim).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict()) # This will copy the weights of the policy network to the target network\n",
    "\n",
    "    optimizer = torch.optim.Adam(policy_net.parameters(), lr=lr) # The optimizer will update ONLY the parameters of the policy network\n",
    "\n",
    "    loss_fn = nn.SmoothL1Loss()  \n",
    "    #============================================LOOP============================================================================================\n",
    "    \n",
    "    \n",
    "    dis_acc = params.get(\"discrete_acc\");\n",
    "    dis_steer_ang = params.get(\"discrete_steer\");\n",
    "    EPISODES = 100;\n",
    "    episode_durations=[];\n",
    "    score = 0 \n",
    "    for i in range(EPISODES):\n",
    "        obs = env.reset()\n",
    "        action = dis_steer_ang[0]\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        print(next_state)\n",
    "        print(info)\n",
    "        s= next_state # example [ 5.23002378e+00 -6.65688906e-01  4.13617835e-08  0.00000000e+00]\n",
    "        vehicle_front = info.get(\"vehicle_front\")\n",
    "        position = info.get(\"position\")[0]\n",
    "        angular_vel = info.get(\"angular_vel\")\n",
    "        angular_vel_x = angular_vel[0]\n",
    "        angular_vel_y = angular_vel[1]\n",
    "        angular_vel_z = angular_vel[2]\n",
    "        acceleration = info.get(\"acceleration\")\n",
    "        steer = info.get(\"steer\")\n",
    "        state = [s, vehicle_front, position, angular_vel_x, angular_vel_y, angular_vel_z, acceleration, steer]\n",
    "        while done == False:\n",
    "            action = choose_action_softmax(policy_net, state, temperature=tau)\n",
    "            next_state, reward,done,info = env.step(action)\n",
    "            score += reward \n",
    "            #Get State \n",
    "            s= next_state.get(\"state\") # example [ 5.23002378e+00 -6.65688906e-01  4.13617835e-08  0.00000000e+00]\n",
    "            vehicle_front = info.get(\"vehicle_front\")\n",
    "            position = info.get(\"position\")[0]\n",
    "            angular_vel = info.get(\"angular_vel\")\n",
    "            angular_vel_x = angular_vel[0]\n",
    "            angular_vel_y = angular_vel[1]\n",
    "            angular_vel_z = angular_vel[2]\n",
    "            acceleration = info.get(\"acceleration\")\n",
    "            steer = info.get(\"steer\")\n",
    "            state = [s, vehicle_front, position, angular_vel_x, angular_vel_y, angular_vel_z, acceleration, steer]\n",
    "            \n",
    "            # Update the replay memory\n",
    "            replay_mem.push(state, action, next_state, reward, done)\n",
    "            \n",
    "            if len(replay_mem) > min_samples_for_training: # we enable the training only if we have enough samples in the replay memory, otherwise the training will use the same samples too often\n",
    "                  update_step(policy_net, target_net, replay_mem, gamma, optimizer, loss_fn, batch_size)\n",
    "                    \n",
    "            state = nextr_state\n",
    "            \n",
    "        if episode_num % target_net_update_steps == 0:\n",
    "            print('Updating target network...')\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "            \n",
    "    env.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
